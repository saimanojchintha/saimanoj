{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reading & Data Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Style</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Season</th>\n",
       "      <th>NeckLine</th>\n",
       "      <th>SleeveLength</th>\n",
       "      <th>Material</th>\n",
       "      <th>FabricType</th>\n",
       "      <th>Decoration</th>\n",
       "      <th>Pattern Type</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.6</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>animal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>Petal</td>\n",
       "      <td>microfiber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>animal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>vintage</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>print</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>L</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>silk</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>embroidary</td>\n",
       "      <td>print</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>cute</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.5</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>chiffonfabric</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>bow</td>\n",
       "      <td>dot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dress_ID    Style    Price  Rating Size  Season NeckLine SleeveLength  \\\n",
       "0  1006032852     Sexy      Low     4.6    M  Summer   o-neck    sleevless   \n",
       "1  1212192089   Casual      Low     0.0    L  Summer   o-neck        Petal   \n",
       "2  1190380701  vintage     High     0.0    L  Automn   o-neck         full   \n",
       "3   966005983    Brief  Average     4.6    L  Spring   o-neck         full   \n",
       "4   876339541     cute      Low     4.5    M  Summer   o-neck    butterfly   \n",
       "\n",
       "        Material FabricType  Decoration Pattern Type  Recommendation  \n",
       "0            NaN    chiffon     ruffles       animal               1  \n",
       "1     microfiber        NaN     ruffles       animal               0  \n",
       "2       polyster        NaN         NaN        print               0  \n",
       "3           silk    chiffon  embroidary        print               1  \n",
       "4  chiffonfabric    chiffon         bow          dot               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data in pandas\n",
    "inp0= pd.read_csv(r\"C:\\Users\\sairam\\Desktop\\New folder\\Data_Analysis_Project\\Data_Analysis_Project\\Attribute DataSet.csv\")\n",
    "inp1= pd.read_csv(r\"C:\\Users\\sairam\\Desktop\\New folder\\Data_Analysis_Project\\Data_Analysis_Project\\Dress Sales.csv\")\n",
    "inp0.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>29-08-2013</th>\n",
       "      <th>31-08-2013</th>\n",
       "      <th>09-02-2013</th>\n",
       "      <th>09-04-2013</th>\n",
       "      <th>09-06-2013</th>\n",
       "      <th>09-08-2013</th>\n",
       "      <th>09-10-2013</th>\n",
       "      <th>09-12-2013</th>\n",
       "      <th>14-09-2013</th>\n",
       "      <th>...</th>\n",
       "      <th>24-09-2013</th>\n",
       "      <th>26-09-2013</th>\n",
       "      <th>28-09-2013</th>\n",
       "      <th>30-09-2013</th>\n",
       "      <th>10-02-2013</th>\n",
       "      <th>10-04-2013</th>\n",
       "      <th>10-06-2013</th>\n",
       "      <th>10-08-2013</th>\n",
       "      <th>10-10-2013</th>\n",
       "      <th>10-12-2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>2114</td>\n",
       "      <td>2274</td>\n",
       "      <td>2491</td>\n",
       "      <td>2660</td>\n",
       "      <td>2727</td>\n",
       "      <td>2887</td>\n",
       "      <td>2930</td>\n",
       "      <td>3119</td>\n",
       "      <td>3204</td>\n",
       "      <td>...</td>\n",
       "      <td>3554</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>3706</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>3795.0</td>\n",
       "      <td>3832.0</td>\n",
       "      <td>3897</td>\n",
       "      <td>3923.0</td>\n",
       "      <td>3985.0</td>\n",
       "      <td>4048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>151</td>\n",
       "      <td>275</td>\n",
       "      <td>570</td>\n",
       "      <td>750</td>\n",
       "      <td>813</td>\n",
       "      <td>1066</td>\n",
       "      <td>1164</td>\n",
       "      <td>1558</td>\n",
       "      <td>1756</td>\n",
       "      <td>...</td>\n",
       "      <td>2710</td>\n",
       "      <td>2942.0</td>\n",
       "      <td>3258</td>\n",
       "      <td>3354.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>3654.0</td>\n",
       "      <td>3911</td>\n",
       "      <td>4024.0</td>\n",
       "      <td>4125.0</td>\n",
       "      <td>4277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>1005</td>\n",
       "      <td>1128</td>\n",
       "      <td>1326</td>\n",
       "      <td>1455</td>\n",
       "      <td>1507</td>\n",
       "      <td>1621</td>\n",
       "      <td>1637</td>\n",
       "      <td>1723</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>1878</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>1914</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1952</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>996</td>\n",
       "      <td>1175</td>\n",
       "      <td>1304</td>\n",
       "      <td>1396</td>\n",
       "      <td>1432</td>\n",
       "      <td>1559</td>\n",
       "      <td>1570</td>\n",
       "      <td>1638</td>\n",
       "      <td>1655</td>\n",
       "      <td>...</td>\n",
       "      <td>2032</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>2252</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>2387.0</td>\n",
       "      <td>2459.0</td>\n",
       "      <td>2544</td>\n",
       "      <td>2614.0</td>\n",
       "      <td>2693.0</td>\n",
       "      <td>2736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dress_ID  29-08-2013  31-08-2013  09-02-2013  09-04-2013  09-06-2013  \\\n",
       "0  1006032852        2114        2274        2491        2660        2727   \n",
       "1  1212192089         151         275         570         750         813   \n",
       "2  1190380701           6           7           7           7           8   \n",
       "3   966005983        1005        1128        1326        1455        1507   \n",
       "4   876339541         996        1175        1304        1396        1432   \n",
       "\n",
       "   09-08-2013  09-10-2013 09-12-2013 14-09-2013  ... 24-09-2013 26-09-2013  \\\n",
       "0        2887        2930       3119       3204  ...       3554     3624.0   \n",
       "1        1066        1164       1558       1756  ...       2710     2942.0   \n",
       "2           8           9         10         10  ...         11       11.0   \n",
       "3        1621        1637       1723       1746  ...       1878     1892.0   \n",
       "4        1559        1570       1638       1655  ...       2032     2156.0   \n",
       "\n",
       "  28-09-2013 30-09-2013  10-02-2013  10-04-2013  10-06-2013  10-08-2013  \\\n",
       "0       3706     3746.0      3795.0      3832.0        3897      3923.0   \n",
       "1       3258     3354.0      3475.0      3654.0        3911      4024.0   \n",
       "2         11       11.0        11.0        11.0          11        11.0   \n",
       "3       1914     1924.0      1929.0      1941.0        1952      1955.0   \n",
       "4       2252     2312.0      2387.0      2459.0        2544      2614.0   \n",
       "\n",
       "   10-10-2013  10-12-2013  \n",
       "0      3985.0        4048  \n",
       "1      4125.0        4277  \n",
       "2        11.0          11  \n",
       "3      1959.0        1963  \n",
       "4      2693.0        2736  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have “Attribute DataSet” which contains a column named “Price”. Choose the correct statement from the following about its data type and variable type.\n",
    "- Integer type and numerical variable\n",
    "- Object type and categorical ordinal variable\n",
    "- Object type and categorical nominal variable\n",
    "- Float type and categorical variable.\n",
    "\n",
    "\n",
    "ANS: Object type and categorical nominal variable\n",
    "\n",
    "reason:\n",
    "\n",
    "        nominal variable is a variable which are unordered categories which are used to classify data without any implied order.here, in \"price\" column we can see that the data is classified to types like average,high,low ..... but those are not following any specific order. so they are \"object type and nominal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another column in “Attribute DataSet” named as “Recommendation”, choose the correct statement about its data type and variable type.\n",
    "- Integer type and categorical\n",
    "- Object type and categorical\n",
    "- Integer type and continuous numerical\n",
    "- Object type only.\n",
    "\n",
    "ANS: Integer type and continuos numericals\n",
    "reason:\n",
    "\n",
    "       As we see,that the values in the \"recommendation\" column are of of datatype \"Integer\" and it is a continuos variabel which mean-A continuous variable is a type of quantitative variable that can take on any value within a certain range or interval. It is a variable that can be measured on a continuous scale, meaning that there are an infinite number of possible values between any two points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following column do you think are of no use in “Attribute DataSet”.\n",
    "- Dress_ID\n",
    "- Price\n",
    "- Size and material\n",
    "- NeckLine\n",
    "- None of the above\n",
    "\n",
    "ANS: None of the above\n",
    "\n",
    "reason:\n",
    "     everything mentioned in the above options are to be needed in the attribute dataset. because, dress_id is needed to know the exact dress(for ex:every dress has an unique dress_id), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the information about the attributes of inp0 and inp1.\n",
    "inp0.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the Rows and Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a column in “Attribute Dataset” named as ‘Size’. This column contains the values in abbreviation format. Write a code in Python to convert the followings:\n",
    "\n",
    "- M into  “Medium”\n",
    "- L into  “Large”\n",
    "- XL into “Extra large”\n",
    "- free into “Free”\n",
    "- S, s & small into “Small”.\n",
    "\n",
    "Now once you are done with changes in the dataset, what is the value of the lowest percentage, the highest percentage and the percentage of Small size categories in the column named “Size”?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest Percentage: 16.666666666666664\n",
      "Highest Percentage: 33.33333333333333\n",
      "Percentage of Small size categories: 33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Creating a sample DataFrame for demonstration\n",
    "data = {'Size': ['M', 'L', 'XL', 'free', 'S', 's', 'small', 'M', 'L', 'S', 'XL', 'free']}\n",
    "inp0 = pd.DataFrame(data)\n",
    "\n",
    "# Mapping abbreviations to full names\n",
    "size_mapping = {'M': 'Medium', 'L': 'Large', 'XL': 'Extra large', 'free': 'Free', 'S': 'Small', 's': 'Small', 'small': 'Small'}\n",
    "\n",
    "# Applying the mapping to the 'Size' column\n",
    "inp0['Size'] = inp0['Size'].map(size_mapping)\n",
    "\n",
    "# Calculating percentages\n",
    "total_rows = len(inp0)\n",
    "small_size_percentage = (inp0['Size'].value_counts(normalize=True).get('Small', 0)) * 100\n",
    "lowest_percentage = inp0['Size'].value_counts(normalize=True).min() * 100\n",
    "highest_percentage = inp0['Size'].value_counts(normalize=True).max() * 100\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Lowest Percentage:\", lowest_percentage)\n",
    "print(\"Highest Percentage:\", highest_percentage)\n",
    "print(\"Percentage of Small size categories:\", small_size_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each size category:\n",
      "Size\n",
      "Small          33.333333\n",
      "Medium         16.666667\n",
      "Large          16.666667\n",
      "Extra large    16.666667\n",
      "Free           16.666667\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#question: Column fixing, correcting size abbreviation. count the percentage of each size category in \"Size\" column.\n",
    "\n",
    "# Creating a sample DataFrame for demonstration\n",
    "data = {'Size': ['M', 'L', 'XL', 'free', 'S', 's', 'small', 'M', 'L', 'S', 'XL', 'free']}\n",
    "inp0 = pd.DataFrame(data)\n",
    "\n",
    "# Mapping abbreviations to full names\n",
    "size_mapping = {'M': 'Medium', 'L': 'Large', 'XL': 'Extra large', 'free': 'Free', 'S': 'Small', 's': 'Small', 'small': 'Small'}\n",
    "\n",
    "# Fixing the 'Size' column\n",
    "inp0['Size'] = inp0['Size'].map(size_mapping)\n",
    "\n",
    "# Counting the percentage of each size category\n",
    "size_percentage = inp0['Size'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Percentage of each size category:\")\n",
    "print(size_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Size\n",
       "M        171\n",
       "free     165\n",
       "L         93\n",
       "S         34\n",
       "XL        14\n",
       "small      1\n",
       "s          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question: Print the value counts of each category in \"Size\" column.\n",
    "\n",
    "\n",
    "inp0= pd.read_csv(r\"C:\\Users\\sairam\\Desktop\\New folder\\Data_Analysis_Project\\Data_Analysis_Project\\Attribute DataSet.csv\")\n",
    "inp0.Size.value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute/Remove Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID            0\n",
       "Style               0\n",
       "Price               2\n",
       "Rating              0\n",
       "Size                0\n",
       "Season              2\n",
       "NeckLine            3\n",
       "SleeveLength        2\n",
       "Material          119\n",
       "FabricType        256\n",
       "Decoration        224\n",
       "Pattern Type      102\n",
       "Recommendation      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null count of each variables of inp0 and inp1.\n",
    "inp0.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID        0\n",
       "29-08-2013      0\n",
       "31-08-2013      0\n",
       "09-02-2013      0\n",
       "09-04-2013      0\n",
       "09-06-2013      0\n",
       "09-08-2013      0\n",
       "09-10-2013      0\n",
       "09-12-2013      0\n",
       "14-09-2013      0\n",
       "16-09-2013      0\n",
       "18-09-2013      0\n",
       "20-09-2013      0\n",
       "22-09-2013      0\n",
       "24-09-2013      0\n",
       "26-09-2013    222\n",
       "28-09-2013      0\n",
       "30-09-2013    257\n",
       "10-02-2013    259\n",
       "10-04-2013    258\n",
       "10-06-2013      0\n",
       "10-08-2013    255\n",
       "10-10-2013    255\n",
       "10-12-2013      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given another dataset named “Dress Sales”. Now if you observe the datatypes of the columns using ‘inp1.info()’ command, you can identify that there are certain columns defined as object data type though they primarily consist of numeric data.\n",
    "\n",
    "Now if you try and convert these object data type columns into numeric data type(float), you will come across an error message. Try to correct this error.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID        int64\n",
       "29-08-2013      int64\n",
       "31-08-2013      int64\n",
       "09-02-2013      int64\n",
       "09-04-2013      int64\n",
       "09-06-2013      int64\n",
       "09-08-2013      int64\n",
       "09-10-2013      int64\n",
       "09-12-2013     object\n",
       "14-09-2013     object\n",
       "16-09-2013     object\n",
       "18-09-2013     object\n",
       "20-09-2013     object\n",
       "22-09-2013     object\n",
       "24-09-2013      int64\n",
       "26-09-2013    float64\n",
       "28-09-2013      int64\n",
       "30-09-2013    float64\n",
       "10-02-2013    float64\n",
       "10-04-2013    float64\n",
       "10-06-2013      int64\n",
       "10-08-2013    float64\n",
       "10-10-2013    float64\n",
       "10-12-2013      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question: Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "\n",
    "inp1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dress_ID  29-08-2013  31-08-2013  09-02-2013  09-04-2013  09-06-2013  \\\n",
      "0    1006032852        2114        2274        2491        2660        2727   \n",
      "1    1212192089         151         275         570         750         813   \n",
      "2    1190380701           6           7           7           7           8   \n",
      "3     966005983        1005        1128        1326        1455        1507   \n",
      "4     876339541         996        1175        1304        1396        1432   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "474   990559192           0           0           0          60          62   \n",
      "475   713391965           0           0           0         560         554   \n",
      "476   532874347           0           0           0         734         728   \n",
      "477   655464934           0           0           0         254         259   \n",
      "478   919930954           0           0           0         538         545   \n",
      "\n",
      "     09-08-2013  09-10-2013  09-12-2013  14-09-2013  ...  24-09-2013  \\\n",
      "0          2887        2930      3119.0      3204.0  ...        3554   \n",
      "1          1066        1164      1558.0      1756.0  ...        2710   \n",
      "2             8           9        10.0        10.0  ...          11   \n",
      "3          1621        1637      1723.0      1746.0  ...        1878   \n",
      "4          1559        1570      1638.0      1655.0  ...        2032   \n",
      "..          ...         ...         ...         ...  ...         ...   \n",
      "474          64          65        67.0        68.0  ...          73   \n",
      "475         544         537       525.0       519.0  ...         400   \n",
      "476         726         715       694.0       690.0  ...         616   \n",
      "477         261         263       268.0       270.0  ...         257   \n",
      "478         558         563       578.0       585.0  ...         628   \n",
      "\n",
      "     26-09-2013  28-09-2013  30-09-2013  10-02-2013  10-04-2013  10-06-2013  \\\n",
      "0        3624.0        3706      3746.0      3795.0      3832.0        3897   \n",
      "1        2942.0        3258      3354.0      3475.0      3654.0        3911   \n",
      "2          11.0          11        11.0        11.0        11.0          11   \n",
      "3        1892.0        1914      1924.0      1929.0      1941.0        1952   \n",
      "4        2156.0        2252      2312.0      2387.0      2459.0        2544   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "474        74.0          75        75.0        76.0        76.0          77   \n",
      "475       388.0         360       364.0       372.0       377.0         380   \n",
      "476       597.0         586       569.0       561.0       555.0         551   \n",
      "477       256.0         255       254.0       253.0       250.0         249   \n",
      "478       632.0         639       645.0       651.0       655.0         660   \n",
      "\n",
      "     10-08-2013  10-10-2013  10-12-2013  \n",
      "0        3923.0      3985.0        4048  \n",
      "1        4024.0      4125.0        4277  \n",
      "2          11.0        11.0          11  \n",
      "3        1955.0      1959.0        1963  \n",
      "4        2614.0      2693.0        2736  \n",
      "..          ...         ...         ...  \n",
      "474        77.0        77.0          77  \n",
      "475       382.0       384.0         285  \n",
      "476       546.0       535.0         520  \n",
      "477       249.0       249.0         248  \n",
      "478       668.0       674.0         680  \n",
      "\n",
      "[479 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#question: Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "\n",
    "# Assuming inp1 is my DataFrame\n",
    "columns_to_convert = ['09-12-2013', '14-09-2013', '16-09-2013', '18-09-2013', '20-09-2013', '22-09-2013']\n",
    "\n",
    "# Convert each specified column to float, handling errors with 'coerce'\n",
    "for column in columns_to_convert:\n",
    "    try:\n",
    "        inp1[column] = pd.to_numeric(inp1[column], errors='coerce', downcast='float')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting column {column}: {e}\")\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(inp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID        0\n",
       "29-08-2013      0\n",
       "31-08-2013      0\n",
       "09-02-2013      0\n",
       "09-04-2013      0\n",
       "09-06-2013      0\n",
       "09-08-2013      0\n",
       "09-10-2013      0\n",
       "09-12-2013      0\n",
       "14-09-2013      0\n",
       "16-09-2013      0\n",
       "18-09-2013      0\n",
       "20-09-2013      0\n",
       "22-09-2013      0\n",
       "24-09-2013      0\n",
       "26-09-2013    222\n",
       "28-09-2013      0\n",
       "30-09-2013    257\n",
       "10-02-2013    259\n",
       "10-04-2013    258\n",
       "10-06-2013      0\n",
       "10-08-2013    255\n",
       "10-10-2013    255\n",
       "10-12-2013      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question: Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "\n",
    "inp1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID        int64\n",
       "29-08-2013      int64\n",
       "31-08-2013      int64\n",
       "09-02-2013      int64\n",
       "09-04-2013      int64\n",
       "09-06-2013      int64\n",
       "09-08-2013      int64\n",
       "09-10-2013      int64\n",
       "09-12-2013    float32\n",
       "14-09-2013    float32\n",
       "16-09-2013    float32\n",
       "18-09-2013    float32\n",
       "20-09-2013    float32\n",
       "22-09-2013    float32\n",
       "24-09-2013      int64\n",
       "26-09-2013    float64\n",
       "28-09-2013      int64\n",
       "30-09-2013    float64\n",
       "10-02-2013    float64\n",
       "10-04-2013    float64\n",
       "10-06-2013      int64\n",
       "10-08-2013    float64\n",
       "10-10-2013    float64\n",
       "10-12-2013      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the object type columns in \"Dress Sales\" into float type of data type.\n",
    "\n",
    "inp1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you see the null counts in “Dress Sales” dataset after performing all the operations that have been mentioned in jupyter notebook, you will find that there are some columns in “Dress Sales” data where there are more than 40% of missing values. Based on your understanding of dealing with missing values do the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Percentage for each column:\n",
      "Dress_ID       0.000000\n",
      "29-08-2013     0.000000\n",
      "31-08-2013     0.000000\n",
      "09-02-2013     0.000000\n",
      "09-04-2013     0.000000\n",
      "09-06-2013     0.000000\n",
      "09-08-2013     0.000000\n",
      "09-10-2013     0.000000\n",
      "09-12-2013     0.208768\n",
      "14-09-2013     0.208768\n",
      "16-09-2013     0.208768\n",
      "18-09-2013     0.208768\n",
      "20-09-2013     0.208768\n",
      "22-09-2013     0.208768\n",
      "24-09-2013     0.000000\n",
      "26-09-2013    46.346555\n",
      "28-09-2013     0.000000\n",
      "30-09-2013    53.653445\n",
      "10-02-2013    54.070981\n",
      "10-04-2013    53.862213\n",
      "10-06-2013     0.000000\n",
      "10-08-2013    53.235908\n",
      "10-10-2013    53.235908\n",
      "10-12-2013     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "null_percentage = inp1.isnull().mean() * 100\n",
    "\n",
    "# Display the null percentage for each column\n",
    "print(\"Null Percentage for each column:\")\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after dropping columns with more than 40% missing values:\n",
      "     Dress_ID  29-08-2013  31-08-2013  09-02-2013  09-04-2013  09-06-2013  \\\n",
      "0  1006032852        2114        2274        2491        2660        2727   \n",
      "1  1212192089         151         275         570         750         813   \n",
      "2  1190380701           6           7           7           7           8   \n",
      "3   966005983        1005        1128        1326        1455        1507   \n",
      "4   876339541         996        1175        1304        1396        1432   \n",
      "\n",
      "   09-08-2013  09-10-2013  09-12-2013  14-09-2013  16-09-2013  18-09-2013  \\\n",
      "0        2887        2930      3119.0      3204.0      3277.0      3321.0   \n",
      "1        1066        1164      1558.0      1756.0      1878.0      1985.0   \n",
      "2           8           9        10.0        10.0        10.0        10.0   \n",
      "3        1621        1637      1723.0      1746.0      1783.0      1796.0   \n",
      "4        1559        1570      1638.0      1655.0      1681.0      1743.0   \n",
      "\n",
      "   20-09-2013  22-09-2013  24-09-2013  28-09-2013  10-06-2013  10-12-2013  \n",
      "0      3386.0      3479.0        3554        3706        3897        4048  \n",
      "1      2106.0      2454.0        2710        3258        3911        4277  \n",
      "2        10.0        11.0          11          11          11          11  \n",
      "3      1812.0      1845.0        1878        1914        1952        1963  \n",
      "4      1824.0      1919.0        2032        2252        2544        2736  \n"
     ]
    }
   ],
   "source": [
    "#question: Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "\n",
    "threshold = 40  # Set the threshold for missing values\n",
    "\n",
    "# Calculate the null percentage for each column\n",
    "null_percentage = inp1.isnull().mean() * 100\n",
    "\n",
    "# Identify columns with more than 40% missing values\n",
    "columns_to_drop = null_percentage[null_percentage > threshold].index\n",
    "\n",
    "# Drop columns with more than 40% missing values\n",
    "inp1 = inp1.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"DataFrame after dropping columns with more than 40% missing values:\")\n",
    "print(inp1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should categorise the dates into seasons in “Dress Sales” data to simplify the analysis according to the following criteria:\n",
    "- June, July and August: Summer.\n",
    "- September, October and November: Autumn.\n",
    "- December, January and February: WInter.\n",
    "- March, April and May: Spring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>29-08-2013</th>\n",
       "      <th>31-08-2013</th>\n",
       "      <th>09-02-2013</th>\n",
       "      <th>09-04-2013</th>\n",
       "      <th>09-06-2013</th>\n",
       "      <th>09-08-2013</th>\n",
       "      <th>09-10-2013</th>\n",
       "      <th>09-12-2013</th>\n",
       "      <th>14-09-2013</th>\n",
       "      <th>...</th>\n",
       "      <th>24-09-2013_Season</th>\n",
       "      <th>26-09-2013_Season</th>\n",
       "      <th>28-09-2013_Season</th>\n",
       "      <th>30-09-2013_Season</th>\n",
       "      <th>10-02-2013_Season</th>\n",
       "      <th>10-04-2013_Season</th>\n",
       "      <th>10-06-2013_Season</th>\n",
       "      <th>10-08-2013_Season</th>\n",
       "      <th>10-10-2013_Season</th>\n",
       "      <th>10-12-2013_Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>2114</td>\n",
       "      <td>2274</td>\n",
       "      <td>2491</td>\n",
       "      <td>2660</td>\n",
       "      <td>2727</td>\n",
       "      <td>2887</td>\n",
       "      <td>2930</td>\n",
       "      <td>3119</td>\n",
       "      <td>3204</td>\n",
       "      <td>...</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>151</td>\n",
       "      <td>275</td>\n",
       "      <td>570</td>\n",
       "      <td>750</td>\n",
       "      <td>813</td>\n",
       "      <td>1066</td>\n",
       "      <td>1164</td>\n",
       "      <td>1558</td>\n",
       "      <td>1756</td>\n",
       "      <td>...</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>1005</td>\n",
       "      <td>1128</td>\n",
       "      <td>1326</td>\n",
       "      <td>1455</td>\n",
       "      <td>1507</td>\n",
       "      <td>1621</td>\n",
       "      <td>1637</td>\n",
       "      <td>1723</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>996</td>\n",
       "      <td>1175</td>\n",
       "      <td>1304</td>\n",
       "      <td>1396</td>\n",
       "      <td>1432</td>\n",
       "      <td>1559</td>\n",
       "      <td>1570</td>\n",
       "      <td>1638</td>\n",
       "      <td>1655</td>\n",
       "      <td>...</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dress_ID  29-08-2013  31-08-2013  09-02-2013  09-04-2013  09-06-2013  \\\n",
       "0  1006032852        2114        2274        2491        2660        2727   \n",
       "1  1212192089         151         275         570         750         813   \n",
       "2  1190380701           6           7           7           7           8   \n",
       "3   966005983        1005        1128        1326        1455        1507   \n",
       "4   876339541         996        1175        1304        1396        1432   \n",
       "\n",
       "   09-08-2013  09-10-2013 09-12-2013 14-09-2013  ... 24-09-2013_Season  \\\n",
       "0        2887        2930       3119       3204  ...            Autumn   \n",
       "1        1066        1164       1558       1756  ...            Autumn   \n",
       "2           8           9         10         10  ...            Autumn   \n",
       "3        1621        1637       1723       1746  ...            Autumn   \n",
       "4        1559        1570       1638       1655  ...            Autumn   \n",
       "\n",
       "  26-09-2013_Season 28-09-2013_Season 30-09-2013_Season  10-02-2013_Season  \\\n",
       "0            Autumn            Autumn            Autumn             Winter   \n",
       "1            Autumn            Autumn            Autumn             Winter   \n",
       "2            Autumn            Autumn            Autumn             Winter   \n",
       "3            Autumn            Autumn            Autumn             Winter   \n",
       "4            Autumn            Autumn            Autumn             Winter   \n",
       "\n",
       "   10-04-2013_Season  10-06-2013_Season  10-08-2013_Season  10-10-2013_Season  \\\n",
       "0             Spring             Summer             Summer             Autumn   \n",
       "1             Spring             Summer             Summer             Autumn   \n",
       "2             Spring             Summer             Summer             Autumn   \n",
       "3             Spring             Summer             Summer             Autumn   \n",
       "4             Spring             Summer             Summer             Autumn   \n",
       "\n",
       "   10-12-2013_Season  \n",
       "0             Winter  \n",
       "1             Winter  \n",
       "2             Winter  \n",
       "3             Winter  \n",
       "4             Winter  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question: Create the four seasons columns in inp1, according to the above criteria.\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "inp1= pd.read_csv(r\"C:\\Users\\sairam\\Desktop\\New folder\\Data_Analysis_Project\\Data_Analysis_Project\\Dress Sales.csv\")\n",
    "\n",
    "# Function to categorize seasons\n",
    "def categorize_season(date_str):\n",
    "    date_format = \"%d-%m-%Y\"  # Corrected the date format\n",
    "    date = datetime.strptime(date_str, date_format)\n",
    "\n",
    "    if (date.month >= 6 and date.month <= 8):  # Summer\n",
    "        return \"Summer\"\n",
    "    elif (date.month >= 9 and date.month <= 11):  # Autumn\n",
    "        return \"Autumn\"\n",
    "    elif (date.month == 12 or (date.month >= 1 and date.month <= 2)):  # Winter\n",
    "        return \"Winter\"\n",
    "    else:  # Spring\n",
    "        return \"Spring\"\n",
    "\n",
    "# Apply the function to create new columns for each season\n",
    "for col in inp1.columns[1:]:  # Skip the first column 'Dress_ID'\n",
    "    inp1[f'{col}_Season'] = inp1[col].apply(lambda x: categorize_season(col))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#print(inp1)\n",
    "inp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                   Dress_ID  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season                 \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter             432173899433   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               29-08-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                  94883   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               31-08-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                 100483   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               09-02-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                 107081   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               09-04-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                 143600   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               09-06-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                 145973   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               09-08-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                 151620   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               09-10-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                 153328   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                      09-12-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season                                                      \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter             3119155810172316381825111717136590190629344945...   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                      14-09-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season                                                      \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter             3204175610174616551926212117136610219943001504...   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               ...  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season  ...   \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter             ...   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                              24-09-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season              \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                178638   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                              26-09-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season              \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter               75944.0   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                              28-09-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season              \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                186614   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                              30-09-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season              \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter               53483.0   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               10-02-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                54466.0   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               10-04-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                55484.0   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               10-06-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                 198948   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               10-08-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                57890.0   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               10-10-2013  \\\n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season               \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                58825.0   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                               10-12-2013  \n",
      "29-08-2013_Season 31-08-2013_Season 09-02-2013_Season 09-04-2013_Season 09-06-2013_Season 09-08-2013_Season 09-10-2013_Season 09-12-2013_Season 14-09-2013_Season 16-09-2013_Season 18-09-2013_Season 20-09-2013_Season 22-09-2013_Season 24-09-2013_Season 26-09-2013_Season 28-09-2013_Season 30-09-2013_Season 10-02-2013_Season 10-04-2013_Season 10-06-2013_Season 10-08-2013_Season 10-10-2013_Season 10-12-2013_Season              \n",
      "Summer            Summer            Winter            Spring            Summer            Summer            Autumn            Winter            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Autumn            Winter            Spring            Summer            Summer            Autumn            Winter                 207909  \n",
      "\n",
      "[1 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#question: calculate the sum of sales in each seasons in inp1 i.e. \"Dress Sales\".\n",
    "\n",
    "# Calculate the sum of sales for each season\n",
    "inp1_sum_seasons = inp1.groupby(['29-08-2013_Season', '31-08-2013_Season', '09-02-2013_Season',\n",
    "                                 '09-04-2013_Season', '09-06-2013_Season', '09-08-2013_Season',\n",
    "                                 '09-10-2013_Season', '09-12-2013_Season', '14-09-2013_Season',\n",
    "                                 '16-09-2013_Season', '18-09-2013_Season', '20-09-2013_Season',\n",
    "                                 '22-09-2013_Season', '24-09-2013_Season', '26-09-2013_Season',\n",
    "                                 '28-09-2013_Season', '30-09-2013_Season', '10-02-2013_Season',\n",
    "                                 '10-04-2013_Season', '10-06-2013_Season', '10-08-2013_Season',\n",
    "                                 '10-10-2013_Season', '10-12-2013_Season']).sum()\n",
    "\n",
    "# Display the sum of sales for each season\n",
    "print(inp1_sum_seasons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge inp1 with inp0 with left join manner, so that the information of inp0 should remain intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dress_ID    Style    Price  Rating  Size  Season   NeckLine  \\\n",
      "0    1006032852     Sexy      Low     4.6     M  Summer     o-neck   \n",
      "1    1212192089   Casual      Low     0.0     L  Summer     o-neck   \n",
      "2    1190380701  vintage     High     0.0     L  Automn     o-neck   \n",
      "3     966005983    Brief  Average     4.6     L  Spring     o-neck   \n",
      "4     876339541     cute      Low     4.5     M  Summer     o-neck   \n",
      "..          ...      ...      ...     ...   ...     ...        ...   \n",
      "474   990559192    Brief  Average     4.7     M  winter     o-neck   \n",
      "475   713391965   Casual      Low     4.7     M  Spring     o-neck   \n",
      "476   532874347   Casual  Average     4.7     M  Summer     v-neck   \n",
      "477   655464934   Casual  Average     4.6     L  winter  boat-neck   \n",
      "478   919930954   Casual      Low     4.4  free  Summer     v-neck   \n",
      "\n",
      "    SleeveLength       Material  FabricType  ... 24-09-2013 26-09-2013  \\\n",
      "0      sleevless            NaN     chiffon  ...       3554     3624.0   \n",
      "1          Petal     microfiber         NaN  ...       2710     2942.0   \n",
      "2           full       polyster         NaN  ...         11       11.0   \n",
      "3           full           silk     chiffon  ...       1878     1892.0   \n",
      "4      butterfly  chiffonfabric     chiffon  ...       2032     2156.0   \n",
      "..           ...            ...         ...  ...        ...        ...   \n",
      "474   halfsleeve        acrylic     chiffon  ...         73       74.0   \n",
      "475         full       polyster         NaN  ...        400      388.0   \n",
      "476         full         cotton         NaN  ...        616      597.0   \n",
      "477    sleevless           silk  broadcloth  ...        257      256.0   \n",
      "478        short         cotton    Corduroy  ...        628      632.0   \n",
      "\n",
      "     28-09-2013  30-09-2013  10-02-2013  10-04-2013  10-06-2013  10-08-2013  \\\n",
      "0          3706      3746.0      3795.0      3832.0        3897      3923.0   \n",
      "1          3258      3354.0      3475.0      3654.0        3911      4024.0   \n",
      "2            11        11.0        11.0        11.0          11        11.0   \n",
      "3          1914      1924.0      1929.0      1941.0        1952      1955.0   \n",
      "4          2252      2312.0      2387.0      2459.0        2544      2614.0   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "474          75        75.0        76.0        76.0          77        77.0   \n",
      "475         360       364.0       372.0       377.0         380       382.0   \n",
      "476         586       569.0       561.0       555.0         551       546.0   \n",
      "477         255       254.0       253.0       250.0         249       249.0   \n",
      "478         639       645.0       651.0       655.0         660       668.0   \n",
      "\n",
      "     10-10-2013  10-12-2013  \n",
      "0        3985.0        4048  \n",
      "1        4125.0        4277  \n",
      "2          11.0          11  \n",
      "3        1959.0        1963  \n",
      "4        2693.0        2736  \n",
      "..          ...         ...  \n",
      "474        77.0          77  \n",
      "475       384.0         285  \n",
      "476       535.0         520  \n",
      "477       249.0         248  \n",
      "478       674.0         680  \n",
      "\n",
      "[479 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "#question: Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "\n",
    "inp0= pd.read_csv(r\"C:\\Users\\sairam\\Desktop\\New folder\\Data_Analysis_Project\\Data_Analysis_Project\\Attribute DataSet.csv\")\n",
    "inp1= pd.read_csv(r\"C:\\Users\\sairam\\Desktop\\New folder\\Data_Analysis_Project\\Data_Analysis_Project\\Dress Sales.csv\")\n",
    "merged_inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "print(merged_inp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Dress_ID', 'Style', 'Price', 'Rating', 'Size', 'Season', 'NeckLine',\n",
      "       'SleeveLength', 'Material', 'FabricType', 'Decoration', 'Pattern Type',\n",
      "       'Recommendation', '29-08-2013', '31-08-2013', '09-02-2013',\n",
      "       '09-04-2013', '09-06-2013', '09-08-2013', '09-10-2013', '09-12-2013',\n",
      "       '14-09-2013', '16-09-2013', '18-09-2013', '20-09-2013', '22-09-2013',\n",
      "       '24-09-2013', '26-09-2013', '28-09-2013', '30-09-2013', '10-02-2013',\n",
      "       '10-04-2013', '10-06-2013', '10-08-2013', '10-10-2013', '10-12-2013'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_inp0.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dress_ID    Style    Price  Rating  Size  Season   NeckLine  \\\n",
      "0    1006032852     Sexy      Low     4.6     M  Summer     o-neck   \n",
      "1    1212192089   Casual      Low     0.0     L  Summer     o-neck   \n",
      "2    1190380701  vintage     High     0.0     L  Automn     o-neck   \n",
      "3     966005983    Brief  Average     4.6     L  Spring     o-neck   \n",
      "4     876339541     cute      Low     4.5     M  Summer     o-neck   \n",
      "..          ...      ...      ...     ...   ...     ...        ...   \n",
      "474   990559192    Brief  Average     4.7     M  winter     o-neck   \n",
      "475   713391965   Casual      Low     4.7     M  Spring     o-neck   \n",
      "476   532874347   Casual  Average     4.7     M  Summer     v-neck   \n",
      "477   655464934   Casual  Average     4.6     L  winter  boat-neck   \n",
      "478   919930954   Casual      Low     4.4  free  Summer     v-neck   \n",
      "\n",
      "    SleeveLength       Material  FabricType  Decoration Pattern Type  \\\n",
      "0      sleevless            NaN     chiffon     ruffles       animal   \n",
      "1          Petal     microfiber         NaN     ruffles       animal   \n",
      "2           full       polyster         NaN         NaN        print   \n",
      "3           full           silk     chiffon  embroidary        print   \n",
      "4      butterfly  chiffonfabric     chiffon         bow          dot   \n",
      "..           ...            ...         ...         ...          ...   \n",
      "474   halfsleeve        acrylic     chiffon         NaN      striped   \n",
      "475         full       polyster         NaN         NaN        solid   \n",
      "476         full         cotton         NaN        lace        solid   \n",
      "477    sleevless           silk  broadcloth    applique        print   \n",
      "478        short         cotton    Corduroy        lace        solid   \n",
      "\n",
      "     Recommendation  \n",
      "0                 1  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 1  \n",
      "4                 0  \n",
      "..              ...  \n",
      "474               0  \n",
      "475               1  \n",
      "476               1  \n",
      "477               1  \n",
      "478               0  \n",
      "\n",
      "[479 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Now Drop the Date columns from inp0 as it is already combined into four seasons.\n",
    "# Drop the Date columns from inp0\n",
    "date_columns = ['29-08-2013', '31-08-2013', '09-02-2013', '09-04-2013', '09-06-2013', '09-08-2013',\n",
    "                '09-10-2013', '09-12-2013', '14-09-2013', '16-09-2013', '18-09-2013', '20-09-2013',\n",
    "                '22-09-2013', '24-09-2013', '26-09-2013', '28-09-2013', '30-09-2013', '10-02-2013',\n",
    "                '10-04-2013', '10-06-2013', '10-08-2013', '10-10-2013', '10-12-2013']\n",
    "\n",
    "merged_inp0.drop(columns=date_columns, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(merged_inp0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the null count of inp0 to get the idea about the missing values in data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID            0\n",
       "Style               0\n",
       "Price               2\n",
       "Rating              0\n",
       "Size                0\n",
       "Season              2\n",
       "NeckLine            3\n",
       "SleeveLength        2\n",
       "Material          119\n",
       "FabricType        256\n",
       "Decoration        224\n",
       "Pattern Type      102\n",
       "Recommendation      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null count of each columns in inp0 dataframe i.e. combined data frame of inp0 and inp1 without date columns.\n",
    "\n",
    "inp0.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are two types of variables one with a large number of missing values and another is very less number of missing values. These two columns can be categorized as:\n",
    "\n",
    "Type-1: Missing values are very less (around 2 or 3 missing values): Price, Season, NeckLine, SleeveLength, Winter and Autumn. \n",
    "\n",
    "Type-2: Missing values are large in numbers (more than 15%): Material, FabricType, Decoration and Pattern Type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question: Deal with the missing values of Type-1 columns: Price, Season, NeckLine, SleeveLength, Winter and Autumn.\n",
    "\n",
    "inp0['Price'].isnull().sum()\n",
    "inp0['Season'].isnull().sum()\n",
    "inp0['NeckLine'].isnull().sum()\n",
    "inp0['SleeveLength'].isnull().sum()\n",
    "inp0[inp0['Season'].isin(['Winter', 'Summer'])]['Season'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question: Deal with the missing values for Type-2 columns: Material, FabricType, Decoration and Pattern Type.\n",
    "\n",
    "inp0['Material'].isnull().sum()\n",
    "inp0['FabricType'].isnull().sum()\n",
    "inp0['Decoration'].isnull().sum()\n",
    "inp0['Pattern Type'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardise value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the given dataset, there are certain discrepancies with the categorical names such as irregular spellings. Choose the correct option of columns with irregular categories and update them.\n",
    " \n",
    "- Season, NeckLine\n",
    "- Price, Material\n",
    "- fabricType, Decoration\n",
    "- Season, SleeveLength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the spellings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the Spellings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a column named ‘Style’ in ‘Attribute Dataset’ which consists of the different style categories of the women apparels. Certain categories whose total sale is less than 50000 across all the seasons is considered under one single category as ‘Others’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style\n",
      "Others    479\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming inp0 is the DataFrame containing the \"Style\" column\n",
    "# and inp1 is the DataFrame containing the sales information and season columns\n",
    "\n",
    "# Step 1: Merge the two datasets on 'Dress_ID'\n",
    "merged_data = pd.merge(inp0, inp1, on='Dress_ID', how='left')\n",
    "\n",
    "# Step 2: Categorize seasons in inp1\n",
    "def categorize_season(date):\n",
    "    if isinstance(date, str):\n",
    "        date_format = \"%d-%m-%Y\"\n",
    "        try:\n",
    "            date = datetime.strptime(date, date_format)\n",
    "        except ValueError:\n",
    "            return 'Unknown'\n",
    "    elif isinstance(date, datetime):\n",
    "        pass  # Already in datetime format\n",
    "    else:\n",
    "        return None  # Handle other data types\n",
    "\n",
    "    if (date.month >= 6 and date.month <= 8):  # Summer\n",
    "        return \"Summer\"\n",
    "    elif (date.month >= 9 and date.month <= 11):  # Autumn\n",
    "        return \"Autumn\"\n",
    "    elif (date.month == 12 or (date.month >= 1 and date.month <= 2)):  # Winter\n",
    "        return \"Winter\"\n",
    "    else:  # Spring\n",
    "        return \"Spring\"\n",
    "\n",
    "# Apply the function to create new columns for each season\n",
    "for col in inp1.columns[1:]:  # Skip the first column 'Dress_ID'\n",
    "    inp1[f'{col}_Season'] = inp1[col].apply(lambda x: categorize_season(x))\n",
    "\n",
    "# Step 3: Identify styles with total sales less than 50000\n",
    "styles_to_group = merged_data.groupby('Style')['Dress_ID'].count()\n",
    "styles_to_group = styles_to_group[styles_to_group < 50000].index\n",
    "\n",
    "# Step 4: Group styles with less than 50000 sales into 'Others'\n",
    "merged_data['Style'] = merged_data['Style'].apply(lambda x: 'Others' if x in styles_to_group else x)\n",
    "\n",
    "# Verify the changes\n",
    "print(merged_data['Style'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following categories in ‘Style’ column can be grouped into ‘Others’ category? and perform the grouping operation in the notebook for further analysis.\n",
    "- Flare, fashion\n",
    "- Novelty, bohemian\n",
    "- OL, fashion, work\n",
    "- Novelty, fashion, Flare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped\n",
      "Not Grouped    479\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#question: Group \"Style\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n",
    "\n",
    "\n",
    "# Identify styles from the list\n",
    "styles_to_group = ['Flare, fashion', 'Novelty, bohemian', 'OL, fashion, work', 'Novelty, fashion, Flare']\n",
    "\n",
    "# Create a new column 'Grouped' to mark styles that are grouped into 'Others'\n",
    "merged_data['Grouped'] = np.where(merged_data['Style'].isin(styles_to_group), 'Grouped into Others', 'Not Grouped')\n",
    "\n",
    "# Display the count of styles in each category\n",
    "grouped_counts = merged_data['Grouped'].value_counts()\n",
    "print(grouped_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of “cute” and “Others” category in “Style” column in “Attribute DataSet” respectively?\n",
    "- 46%, 5%\n",
    "- 9%, 2.1%\n",
    "- 2.1%, 5%\n",
    "- 13.8%, 9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queston: Calculate the percentage of \"cute\" and \"Others\" categories in \"Style\" column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style\n",
      "Casual      45.720251\n",
      "Sexy        13.778706\n",
      "party       10.647182\n",
      "cute         9.185804\n",
      "vintage      5.219207\n",
      "bohemian     4.801670\n",
      "Brief        3.549061\n",
      "work         3.549061\n",
      "sexy         1.461378\n",
      "Novelty      1.252610\n",
      "Flare        0.417537\n",
      "OL           0.208768\n",
      "fashion      0.208768\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#question: Calculate the percentage of each categories in the \"Style\" variable.\n",
    "\n",
    "# Assuming 'inp0' is the correct dataset\n",
    "# Calculate the percentage of each category in the \"Style\" variable\n",
    "style_percentages = inp0['Style'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the percentages\n",
    "print(style_percentages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly Club Neckline, SLeeve length categories into \"Others\" which have less than 50000 sales across all the seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'TotalSales'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12956\\3570779314.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Assuming 'inp0' is your DataFrame and 'NeckLine' is a column in it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Group \"Neckline\" categories into \"Others\" which have less than 50000 sales across all the seasons.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNeckLine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNeckLine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTotalSales\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Others'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'TotalSales'"
     ]
    }
   ],
   "source": [
    "#question: Group \"Neckline\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n",
    "\n",
    "# Assuming 'inp0' is your DataFrame and 'NeckLine' is a column in it\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_columns = inp0.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Filter out non-numeric values and calculate the total sales for each neckline across all seasons\n",
    "inp0['Total_Sales'] = inp0[numeric_columns].sum(axis=1)\n",
    "\n",
    "# Identify necklines with total sales less than 50000\n",
    "necklines_to_group = inp0.groupby('NeckLine')['Total_Sales'].sum() < 50000\n",
    "\n",
    "# Group specified necklines into 'Others'\n",
    "inp0['NeckLine'] = np.where(inp0['NeckLine'].isin(necklines_to_group[necklines_to_group].index), 'Others', inp0['NeckLine'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question: Group \"Sleeve length\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n",
    "\n",
    "# Assuming 'inp0' is your DataFrame and 'Sleeve length' is a column in it\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_columns = inp0.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Filter out non-numeric values and calculate the total sales for each sleeve length across all seasons\n",
    "inp0['Total_Sales'] = inp0[numeric_columns].sum(axis=1)\n",
    "\n",
    "# Identify sleeve lengths with total sales less than 50000\n",
    "sleeve_lengths_to_group = inp0.groupby('SleeveLength')['Total_Sales'].sum() < 50000\n",
    "\n",
    "# Group specified sleeve lengths into 'Others'\n",
    "inp0['SleeveLength'] = np.where(inp0['SleeveLength'].isin(sleeve_lengths_to_group[sleeve_lengths_to_group].index), 'Others', inp0['SleeveLength'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Club material, fabrictype, patterntype and decoration categories into \"Others\" which have less than 25000 sales across all the seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question: Group \"material\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n",
    "\n",
    "# Calculate total sales for each material across all seasons\n",
    "inp0['Total_Sales'] = inp0[numeric_columns].sum(axis=1)\n",
    "\n",
    "# Identify materials with total sales less than 25000\n",
    "materials_to_group = inp0.groupby('Material')['Total_Sales'].sum() < 25000\n",
    "\n",
    "# Group specified materials into 'Others'\n",
    "inp0['Material'] = np.where(inp0['Material'].isin(materials_to_group[materials_to_group].index), 'Others', inp0['Material'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question: Group \"fabric type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n",
    "\n",
    "# Calculate total sales for each fabric type across all seasons\n",
    "inp0['Total_Sales'] = inp0[numeric_columns].sum(axis=1)\n",
    "\n",
    "# Identify fabric types with total sales less than 25000\n",
    "fabric_types_to_group = inp0.groupby('FabricType')['Total_Sales'].sum() < 25000\n",
    "\n",
    "# Group specified fabric types into 'Others'\n",
    "inp0['FabricType'] = np.where(inp0['FabricType'].isin(fabric_types_to_group[fabric_types_to_group].index), 'Others', inp0['FabricType'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question: Group \"patern type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n",
    "\n",
    "# Calculate total sales for each fabric type across all seasons\n",
    "inp0['Total_Sales'] = inp0[numeric_columns].sum(axis=1)\n",
    "\n",
    "# Identify fabric types with total sales less than 25000\n",
    "fabric_types_to_group = inp0.groupby('Pattern Type')['Total_Sales'].sum() < 25000\n",
    "\n",
    "# Group specified fabric types into 'Others'\n",
    "inp0['Pattern Type'] = np.where(inp0['Pattern Type'].isin(fabric_types_to_group[fabric_types_to_group].index), 'Others', inp0['Pattern Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question: Group \"decoration\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n",
    "\n",
    "# Calculate total sales for each fabric type across all seasons\n",
    "inp0['Total_Sales'] = inp0[numeric_columns].sum(axis=1)\n",
    "\n",
    "# Identify fabric types with total sales less than 25000\n",
    "fabric_types_to_group = inp0.groupby('Decoration')['Total_Sales'].sum() < 25000\n",
    "\n",
    "# Group specified fabric types into 'Others'\n",
    "inp0['Decoration'] = np.where(inp0['Decoration'].isin(fabric_types_to_group[fabric_types_to_group].index), 'Others', inp0['Decoration'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caregorical Ordered Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following is an unordered variable in “Attribute DataSet”.\n",
    "- Style\n",
    "- Price\n",
    "- Season\n",
    "- Size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variable Univariate analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the approximate difference between the maximum value and 75th percentile in “Autumn” column.\n",
    "- Approx 54000\n",
    "- Approx 55000\n",
    "- Approx 52000\n",
    "- Approx 50000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Style</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Season</th>\n",
       "      <th>NeckLine</th>\n",
       "      <th>SleeveLength</th>\n",
       "      <th>Material</th>\n",
       "      <th>FabricType</th>\n",
       "      <th>Decoration</th>\n",
       "      <th>Pattern Type</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.6</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>animal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>Petal</td>\n",
       "      <td>microfiber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>animal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>vintage</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>print</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>L</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>silk</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>embroidary</td>\n",
       "      <td>print</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>cute</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.5</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>chiffonfabric</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>bow</td>\n",
       "      <td>dot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1068332458</td>\n",
       "      <td>bohemian</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>print</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1220707172</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XL</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>cotton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>solid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1113094204</td>\n",
       "      <td>Flare</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.0</td>\n",
       "      <td>free</td>\n",
       "      <td>Spring</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>short</td>\n",
       "      <td>cotton</td>\n",
       "      <td>broadcloth</td>\n",
       "      <td>beading</td>\n",
       "      <td>solid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>985292672</td>\n",
       "      <td>bohemian</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>free</td>\n",
       "      <td>Summer</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>nylon</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1117293701</td>\n",
       "      <td>party</td>\n",
       "      <td>Average</td>\n",
       "      <td>5.0</td>\n",
       "      <td>free</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>broadcloth</td>\n",
       "      <td>lace</td>\n",
       "      <td>solid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>898481530</td>\n",
       "      <td>Flare</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.0</td>\n",
       "      <td>free</td>\n",
       "      <td>Spring</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>short</td>\n",
       "      <td>nylon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>animal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>957723897</td>\n",
       "      <td>sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.7</td>\n",
       "      <td>M</td>\n",
       "      <td>Winter</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>threequarter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>lace</td>\n",
       "      <td>print</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>749031896</td>\n",
       "      <td>vintage</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.8</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>short</td>\n",
       "      <td>cotton</td>\n",
       "      <td>jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>animal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1055411544</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Summer</td>\n",
       "      <td>boat-neck</td>\n",
       "      <td>short</td>\n",
       "      <td>cotton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sashes</td>\n",
       "      <td>solid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1162628131</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>free</td>\n",
       "      <td>Winter</td>\n",
       "      <td>boat-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>lace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>624314841</td>\n",
       "      <td>cute</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.7</td>\n",
       "      <td>L</td>\n",
       "      <td>spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>short</td>\n",
       "      <td>cotton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sashes</td>\n",
       "      <td>solid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>830467746</td>\n",
       "      <td>bohemian</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5.0</td>\n",
       "      <td>free</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hollowout</td>\n",
       "      <td>patchwork</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>840857118</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Winter</td>\n",
       "      <td>peterpan-collor</td>\n",
       "      <td>threequarter</td>\n",
       "      <td>cotton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patchwork</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1113221101</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Average</td>\n",
       "      <td>5.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>milksilk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>861754372</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.5</td>\n",
       "      <td>L</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>cotton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beading</td>\n",
       "      <td>solid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dress_ID     Style    Price  Rating  Size  Season         NeckLine  \\\n",
       "0   1006032852      Sexy      Low     4.6     M  Summer           o-neck   \n",
       "1   1212192089    Casual      Low     0.0     L  Summer           o-neck   \n",
       "2   1190380701   vintage     High     0.0     L  Automn           o-neck   \n",
       "3    966005983     Brief  Average     4.6     L  Spring           o-neck   \n",
       "4    876339541      cute      Low     4.5     M  Summer           o-neck   \n",
       "5   1068332458  bohemian      Low     0.0     M  Summer           v-neck   \n",
       "6   1220707172    Casual  Average     0.0    XL  Summer           o-neck   \n",
       "7   1113094204     Flare  Average     0.0  free  Spring           v-neck   \n",
       "8    985292672  bohemian      Low     0.0  free  Summer           v-neck   \n",
       "9   1117293701     party  Average     5.0  free  Summer           o-neck   \n",
       "10   898481530     Flare  Average     0.0  free  Spring           v-neck   \n",
       "11   957723897      sexy      Low     4.7     M  Winter           o-neck   \n",
       "12   749031896   vintage  Average     4.8     M  Summer           o-neck   \n",
       "13  1055411544    Casual      Low     5.0     M  Summer        boat-neck   \n",
       "14  1162628131    Casual      Low     0.0  free  Winter        boat-neck   \n",
       "15   624314841      cute  Average     4.7     L  spring           o-neck   \n",
       "16   830467746  bohemian   Medium     5.0  free  Automn           o-neck   \n",
       "17   840857118     Brief  Average     0.0     M  Winter  peterpan-collor   \n",
       "18  1113221101      Sexy  Average     5.0     M  Automn           o-neck   \n",
       "19   861754372      Sexy  Average     4.5     L  Automn           o-neck   \n",
       "\n",
       "    SleeveLength       Material  FabricType  Decoration Pattern Type  \\\n",
       "0      sleevless            NaN     chiffon     ruffles       animal   \n",
       "1          Petal     microfiber         NaN     ruffles       animal   \n",
       "2           full       polyster         NaN         NaN        print   \n",
       "3           full           silk     chiffon  embroidary        print   \n",
       "4      butterfly  chiffonfabric     chiffon         bow          dot   \n",
       "5      sleevless            NaN         NaN         NaN        print   \n",
       "6           full         cotton         NaN         NaN        solid   \n",
       "7          short         cotton  broadcloth     beading        solid   \n",
       "8      sleevless          nylon     chiffon         NaN          NaN   \n",
       "9           full       polyster  broadcloth        lace        solid   \n",
       "10         short          nylon         NaN         NaN       animal   \n",
       "11  threequarter            NaN     chiffon        lace        print   \n",
       "12         short         cotton      jersey         NaN       animal   \n",
       "13         short         cotton         NaN      sashes        solid   \n",
       "14          full          other       other        lace          NaN   \n",
       "15         short         cotton         NaN      sashes        solid   \n",
       "16          full            NaN         NaN   hollowout    patchwork   \n",
       "17  threequarter         cotton         NaN         NaN    patchwork   \n",
       "18     sleevless       milksilk         NaN         NaN          NaN   \n",
       "19          full         cotton         NaN     beading        solid   \n",
       "\n",
       "    Recommendation  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "5                0  \n",
       "6                0  \n",
       "7                1  \n",
       "8                1  \n",
       "9                0  \n",
       "10               0  \n",
       "11               1  \n",
       "12               1  \n",
       "13               0  \n",
       "14               0  \n",
       "15               1  \n",
       "16               1  \n",
       "17               0  \n",
       "18               1  \n",
       "19               0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp0.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.045971e+08</td>\n",
       "      <td>4.042857</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.350447e+08</td>\n",
       "      <td>1.789653</td>\n",
       "      <td>0.487950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.494011e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.523870e+08</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.517769e+08</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.882011e+08</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.249825e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dress_ID    Rating  Recommendation\n",
       "count  7.000000e+00  7.000000        7.000000\n",
       "mean   8.045971e+08  4.042857        0.285714\n",
       "std    2.350447e+08  1.789653        0.487950\n",
       "min    5.494011e+08  0.000000        0.000000\n",
       "25%    6.523870e+08  4.550000        0.000000\n",
       "50%    7.517769e+08  4.700000        0.000000\n",
       "75%    8.882011e+08  4.750000        0.500000\n",
       "max    1.249825e+09  5.000000        1.000000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the numerical variale: \"Autumn\".\n",
    "\n",
    "inp0[inp0['Season'] == 'Autumn'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Summer' 'Automn' 'Spring' 'Winter' 'spring' 'winter' nan 'Autumn']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Aotumn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Aotumn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Plot the boxplot using the correct column name and case\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m sns\u001b[38;5;241m.\u001b[39mboxplot(x\u001b[38;5;241m=\u001b[39minp0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeason\u001b[39m\u001b[38;5;124m'\u001b[39m], y\u001b[38;5;241m=\u001b[39minp0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAotumn\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBoxplot of Autumn Column\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Aotumn'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the boxplot of \"Autumn\" column.\n",
    "\n",
    "# Display the unique values in the 'Season' column\n",
    "print(inp0['Season'].unique())\n",
    "\n",
    "# Plot the boxplot using the correct column name and case\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=inp0['Season'], y=inp0['Aotumn'])\n",
    "plt.title('Boxplot of Autumn Column')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following season has the highest difference between the maximum value and 99th quantile of sales?\n",
    "- Winter\n",
    "- Summer\n",
    "- Spring\n",
    "- Autumn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Season'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Season'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#question: Find the maximum and 50th percentile of Winter season.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Filter data for the Winter season\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m winter_data \u001b[38;5;241m=\u001b[39m inp1[inp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeason\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWinter\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate the maximum and 50th percentile for Winter season\u001b[39;00m\n\u001b[0;32m      9\u001b[0m winter_max \u001b[38;5;241m=\u001b[39m winter_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWinter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Season'"
     ]
    }
   ],
   "source": [
    "#question: Find the maximum and 50th percentile of Winter season.\n",
    "\n",
    "\n",
    "\n",
    "# Filter data for the Winter season\n",
    "winter_data = inp1[inp1['Season'] == 'Winter']\n",
    "\n",
    "# Calculate the maximum and 50th percentile for Winter season\n",
    "winter_max = winter_data['Winter'].max()\n",
    "winter_50th_percentile = np.percentile(winter_data['Winter'].dropna(), 50)\n",
    "\n",
    "print(\"Maximum value for Winter season:\", winter_max)\n",
    "print(\"50th Percentile (median) for Winter season:\", winter_50th_percentile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 50th percentile of Summer season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 50th percentile of Spring season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 50th percentile of Autumn season.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
